\documentclass{article}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{float}
\usepackage{enumitem}
\usepackage{forest}

\begin{document}

\title{Homework 4}
\author{Manyara Bonface Baraka - mbaraka}
\date{\today}
\maketitle

\section*{Problem 1: Bayesian Learning}
\textit{Bayesian Learning calculates the probability of  each hypothesis given the data, and makes predictions by weighing all hypothesis by their probabilities}

- Will asssumed eaqual prior start for each hypothesis \(P(h_i) = \frac{1}{6}\) for all i
\subsubsection*{Observations}
\textbf{Plots}
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{../Problem1/num_of_observation.png}
    % \caption{Number of Observations}
    \label{fig:num_of_observation}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{../Problem1/predictive_of_next_head.png}
    % \caption{Number of Observations}
    \label{fig:num_of_observation}
\end{figure}

\textbf{Most likely hypothesis after all observations: h=0.4}

\subsubsection*{Insights}

\textbf{The first plot: Posterior Probability plot}: the plot shows the evolution of the posterior probabilities over time for each hypothesis.
At the start all hypthesis have the same prior however as the observation came in the posterior changes am having the likely of h=0.4.\\
\textbf{The second plot: Predictive Probabilit plot}: the second plot depicts teh predictive probability that the next flip will be heads, calculate after each observation.
The model flactuates at first but it tends to stabilize around 0.4. The highest posterior probabily influences the dominance of the hypthesis on predictions. The predictive 
probability tends to be stable aroung 0.4 since the posterior of h3 becaomes quite large. 


\clearpage

\section*{Problem 2: Maximum a Posteriori (MAP) Estimation}
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{../Problem2/Figure_1.png}
    % \caption{Number of Observations}
    \label{fig:num_of_observation}
\end{figure}

\subsubsection*{Results:}
\textbf{MAP final prediction (Uniform Prior):} 0.4000 \\
\textbf{MAP final prediction (Non-Uniform Prior):} 0.4000

\subsubsection*{Observation and Insights}
\textbf{MAP vs Bayesian}

- Smoothness: Bayesian with the blue dotted it smoothly converge  to the true bias by averagin all hypthesis however, the MAP prediction jumps discretely as the most probable hypothesis changes.

- Prior sensistivity: With the uniform prior MAP predictions astarts at 0 due to limitation in tie-breaking but it adjusts faster as the data comes in. While with non-uniform
prior is biased  MAP initially predicts 0.4 and its constant for that. \\

Generally the MAP is computational efficinte however its prone to abrupt changes and prior bias, especially with limited data. It trades off accuracy for simplicity while Bayesian provides a robust predictions
by combining uncertinity but requires more computation.


\clearpage

\section*{Problem 3: Maximum Likelihood (ML) Estimation}
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{../Problem3/Comparizon_ML_MAP_Bayesian.png}
    % \caption{Number of Observations}
    \label{fig:num_of_observation}
\end{figure}
\begin{itemize}
    \item Is the estimate equal to the estimates we found as a result of Bayesian Learning and MAP estimation? What is the major difference?
    \item Which is likely to be more accurate: the estimate found with ML estimation or the estimate found using the other methods?
    \item In what case (specifically, for what prior distribution) does MAP estimation reduce to the ML estimate? Feel free to consult Section 20.2 Learning with Complete Data in Russel \& Norvig.
    \item Provide a brief discussion comparing Bayesian Learning, MAP, and ML estimation. What are the pros and cons of each?
\end{itemize}

\subsubsection*{Results}
\textbf{Final ML estimate:} 0.3000 \\

\subsubsection*{Discussion}
\begin{itemize}
    \item \textbf{Comparison with Bayesian Learning and MAP:} The ML estimate of 0.3000 differs from the Bayesian and MAP estimates of 0.4000. The major difference lies in the fact that ML estimation does not incorporate prior information, whereas Bayesian and MAP methods do.
    \item \textbf{Accuracy:} The accuracy of ML estimation depends on the amount of data available. With sufficient data, ML can be as accurate as Bayesian or MAP. However, with limited data, Bayesian and MAP are generally more accurate due to their use of prior information.
    \item \textbf{When MAP reduces to ML:} MAP estimation reduces to ML estimation when the prior distribution is uniform, as the prior does not influence the posterior in this case.
    \item \textbf{Comparison of Methods:}
    \begin{itemize}
        \item \textbf{Bayesian Learning:} Provides robust predictions by combining prior knowledge and observed data. It is computationally intensive but handles uncertainty well.
        \item \textbf{MAP Estimation:} Balances prior knowledge and observed data. It is computationally efficient but can be sensitive to the choice of prior.
        \item \textbf{ML Estimation:} Relies solely on observed data, making it simple and computationally efficient. However, it may be less accurate with limited data or noisy observations.
    \end{itemize}
\end{itemize}


\end{document}